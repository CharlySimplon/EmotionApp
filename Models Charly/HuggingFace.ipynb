{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du jeu de donn√©es\n",
    "df = pd.read_csv(\"emotion_dataworld.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"content\": \"review\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop( df[ (df['sentiment'] == 'neutral')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'worry'] = 0\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'happiness'] = 1\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'sadness'] = 0\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'love'] = 1\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'surprise'] = 1\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'fun'] = 1\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'relief'] = 1\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'hate'] = 0\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'empty'] = 0\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'enthusiasm'] = 1\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'boredom'] = 0\n",
      "C:\\Users\\APPREN~1\\AppData\\Local\\Temp/ipykernel_22032/3945871787.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][df['sentiment']== 'anger'] = 0\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'][df['sentiment']== 'worry'] = 0\n",
    "df['sentiment'][df['sentiment']== 'happiness'] = 1\n",
    "df['sentiment'][df['sentiment']== 'sadness'] = 0\n",
    "df['sentiment'][df['sentiment']== 'love'] = 1\n",
    "df['sentiment'][df['sentiment']== 'surprise'] = 1\n",
    "df['sentiment'][df['sentiment']== 'fun'] = 1\n",
    "df['sentiment'][df['sentiment']== 'relief'] = 1\n",
    "df['sentiment'][df['sentiment']== 'hate'] = 0\n",
    "df['sentiment'][df['sentiment']== 'empty'] = 0\n",
    "df['sentiment'][df['sentiment']== 'enthusiasm'] = 1\n",
    "df['sentiment'][df['sentiment']== 'boredom'] = 0\n",
    "df['sentiment'][df['sentiment']== 'anger'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.drop(['index','tweet_id','author'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>0</td>\n",
       "      <td>http://twitpic.com/674p1 - @JTHawthorne this i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>0</td>\n",
       "      <td>is sadly sitting at home when she could be goi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>0</td>\n",
       "      <td>@ArlenesUniverse I have tried. He doesn't want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>0</td>\n",
       "      <td>#twitterfails fucking hard right now...this is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>0</td>\n",
       "      <td>Wishing I could kidnap @candrews from work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8143 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review\n",
       "0             0  @tiffanylue i know  i was listenin to bad habi...\n",
       "1             0  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2             0                Funeral ceremony...gloomy friday...\n",
       "3             1               wants to hang out with friends SOON!\n",
       "4             0  Re-pinging @ghostridah14: why didn't you go to...\n",
       "...         ...                                                ...\n",
       "8138          0  http://twitpic.com/674p1 - @JTHawthorne this i...\n",
       "8139          0  is sadly sitting at home when she could be goi...\n",
       "8140          0  @ArlenesUniverse I have tried. He doesn't want...\n",
       "8141          0  #twitterfails fucking hard right now...this is...\n",
       "8142          0         Wishing I could kidnap @candrews from work\n",
       "\n",
       "[8143 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "reviews = dataset['review'].values.tolist()\n",
    "sentiments = dataset['sentiment'].values.tolist()\n",
    " \n",
    "# On charge l'objet \"tokenizer\"de camemBERT qui va servir a encoder\n",
    "# 'camebert-base' est la version de camembert qu'on choisit d'utiliser\n",
    "# 'do_lower_case' √† True pour qu'on passe tout en miniscule\n",
    "TOKENIZER = BertTokenizer.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    do_lower_case=True)\n",
    " \n",
    "# La fonction batch_encode_plus encode un batch de donnees\n",
    "encoded_batch = TOKENIZER.batch_encode_plus(reviews,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=30,\n",
    "                                            padding=True,\n",
    "                                            truncation=True,\n",
    "                                            return_attention_mask = True,\n",
    "                                            return_tensors = 'pt')\n",
    " \n",
    "# On transforme la liste des sentiments en tenseur\n",
    "sentiments = torch.tensor(sentiments)\n",
    " \n",
    "# On calcule l'indice qui va delimiter nos datasets d'entrainement et de validation\n",
    "# On utilise 80% du jeu de donn√©e pour l'entrainement et les 20% restant pour la validation\n",
    "split_border = int(len(sentiments)*0.8)\n",
    " \n",
    " \n",
    "train_dataset = TensorDataset(\n",
    "    encoded_batch['input_ids'][:split_border],\n",
    "    encoded_batch['attention_mask'][:split_border],\n",
    "    sentiments[:split_border])\n",
    "validation_dataset = TensorDataset(\n",
    "    encoded_batch['input_ids'][split_border:],\n",
    "    encoded_batch['attention_mask'][split_border:],\n",
    "    sentiments[split_border:])\n",
    " \n",
    " \n",
    "batch_size = 128\n",
    " \n",
    "# On cree les DataLoaders d'entrainement et de validation\n",
    "# Le dataloader est juste un objet iterable\n",
    "# On le configure pour iterer le jeu d'entrainement de fa√ßon aleatoire et creer les batchs.\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size)\n",
    " \n",
    "validation_dataloader = DataLoader(\n",
    "            validation_dataset,\n",
    "            sampler = SequentialSampler(validation_dataset),\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# On la version pre-entrainee de camemBERT 'base'\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # Learning Rate\n",
    "                  eps = 1e-8) # Epsilon\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Epoch 1 / 4 ##########\n",
      "Training...\n",
      "  Batch 40  of 51.\n",
      "\n",
      "  Average training loss: 0.57\n",
      "\n",
      "########## Epoch 2 / 4 ##########\n",
      "Training...\n",
      "  Batch 40  of 51.\n",
      "\n",
      "  Average training loss: 0.52\n",
      "\n",
      "########## Epoch 3 / 4 ##########\n",
      "Training...\n",
      "  Batch 40  of 51.\n",
      "\n",
      "  Average training loss: 0.46\n",
      "\n",
      "########## Epoch 4 / 4 ##########\n",
      "Training...\n",
      "  Batch 40  of 51.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# On va stocker nos tensors sur mon cpu : je n'ai pas mieux\n",
    "device = torch.device(\"cpu\")\n",
    " \n",
    "# Pour enregistrer les stats a chaque epoque\n",
    "training_stats = []\n",
    " \n",
    "# Boucle d'entrainement\n",
    "for epoch in range(0, epochs):\n",
    "     \n",
    "    print(\"\")\n",
    "    print(f'########## Epoch {epoch+1} / {epochs} ##########')\n",
    "    print('Training...')\n",
    " \n",
    " \n",
    "    # On initialise la loss pour cette epoque\n",
    "    total_train_loss = 0\n",
    " \n",
    "    # On met le modele en mode 'training'\n",
    "    # Dans ce mode certaines couches du modele agissent differement\n",
    "    model.train()\n",
    " \n",
    "    # Pour chaque batch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    " \n",
    "        # On fait un print chaque 40 batchs\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            print(f'  Batch {step}  of {len(train_dataloader)}.')\n",
    "         \n",
    "        # On recupere les donnees du batch\n",
    "        input_id = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        sentiment = batch[2].to(device)\n",
    " \n",
    "        # On met le gradient a 0\n",
    "        model.zero_grad()        \n",
    " \n",
    "        # On passe la donnee au model et on recupere la loss et le logits (sortie avant fonction d'activation)\n",
    "        loss, logits = model(input_id, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=attention_mask, \n",
    "                             labels=sentiment)\n",
    " \n",
    "        # On incremente la loss totale\n",
    "        # .item() donne la valeur numerique de la loss\n",
    "        total_train_loss += loss.item()\n",
    " \n",
    "        # Backpropagtion\n",
    "        loss.backward()\n",
    " \n",
    "        # On actualise les parametrer grace a l'optimizer\n",
    "        optimizer.step()\n",
    " \n",
    "    # On calcule la  loss moyenne sur toute l'epoque\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)   \n",
    " \n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))  \n",
    "     \n",
    "    # Enregistrement des stats de l'epoque\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "        }\n",
    "    )\n",
    " \n",
    "print(\"Model saved!\")\n",
    "torch.save(model.state_dict(), \"./sentiments.pt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b175033f4bbaf9f0fba1edfe1665e4ba0c526b66dcf284e028a4c2430fd27885"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('devia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
